{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fff8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel, Nmf\n",
    "from gensim.utils import simple_preprocess\n",
    "import zipfile\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras import layers\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import tqdm\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
    "import copy\n",
    "\n",
    "# WIP code part\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# nltk.download('en_core_web_sm')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# load the pre-trained English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "custom_stopwords = set(stopwords.words(\"english\"))\n",
    "custom_stopwords = custom_stopwords.union({\"reuters\", \"bbc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1186c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same one as in the test_environment.py\n",
    "def progress_bar(iteration, total):\n",
    "    total_len = 100\n",
    "    percent_part = (\"{0:.2f}\").format(100 * (iteration / total))\n",
    "    filled = int(total_len * iteration / total)\n",
    "    bar = '█' * filled + '-' * (total_len - filled)\n",
    "    print(f'\\r Progress: [{bar}] {percent_part}%', end='')\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4150b",
   "metadata": {},
   "source": [
    "## NER functions and architecture (transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d668ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        query = tf.reshape(\n",
    "            tf.transpose(tf.reshape(query, (batch_size, -1, self.num_heads, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size * self.num_heads, -1, self.head_dim),\n",
    "        )\n",
    "        key = tf.reshape(\n",
    "            tf.transpose(tf.reshape(key, (batch_size, -1, self.num_heads, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size * self.num_heads, -1, self.head_dim),\n",
    "        )\n",
    "        value = tf.reshape(\n",
    "            tf.transpose(tf.reshape(value, (batch_size, -1, self.num_heads, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size * self.num_heads, -1, self.head_dim),\n",
    "        )\n",
    "\n",
    "        attention_logits = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_logits = attention_logits / tf.math.sqrt(tf.cast(self.head_dim, tf.float32))\n",
    "        attention_weights = tf.nn.softmax(attention_logits, axis=-1)\n",
    "\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        output = tf.reshape(\n",
    "            tf.transpose(tf.reshape(output, (batch_size, self.num_heads, -1, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size, -1, self.embed_dim),\n",
    "        )\n",
    "        output = self.combine_heads(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1518912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                keras.layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        ffn_output = self.ffn(attn_output)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(inputs + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82328b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        maxlen = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        position_embeddings = self.pos_emb(positions)\n",
    "        token_embeddings = self.token_emb(inputs)\n",
    "        return token_embeddings + position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f80fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(keras.Model):\n",
    "    def __init__(\n",
    "        self, num_tags, vocab_size, maxlen=128, embed_dim=32, num_heads=2, ff_dim=32, num_layers=1, rate=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "#         self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.transformer_blocks = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n",
    "        self.dropout1 = layers.Dropout(0.1)\n",
    "        self.ff = layers.Dense(ff_dim, activation=\"relu\")\n",
    "        self.ff_final = layers.Dense(num_tags, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.ff(x)\n",
    "        x = self.ff_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a72977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_model_mode: model we want to use\n",
    "#     - specific_lstm: BiLSTM model trained on CORD19 data\n",
    "#     - general_lstm: BiLSTM model trained on general (topics) data\n",
    "#     - specific_transformer: Transformer-based model trained on CORD19 data\n",
    "#     - general_transformer:Transformer-based model trained on general (topics) data\n",
    "def load_ner(ner_model_mode):\n",
    "    if ner_model_mode == \"specific_lstm\":\n",
    "        pass\n",
    "    elif ner_model_mode == \"general_lstm\":\n",
    "        pass\n",
    "    elif ner_model_mode == \"specific_transformer\":\n",
    "        model = keras.models.load_model('../models/model_cord_transformer/model.tf')\n",
    "\n",
    "        with open('../models/model_cord_transformer/maxlen.pickle', 'rb') as handle:\n",
    "            max_len = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_cord_transformer/tags.pickle', 'rb') as handle:\n",
    "            tags = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_cord_transformer/words.pickle', 'rb') as handle:\n",
    "            word2idx = pickle.load(handle)\n",
    "        \n",
    "        return model, tags, word2idx, max_len\n",
    "    elif ner_model_mode == \"general_transformer\":\n",
    "        model = keras.models.load_model('../models/model_general_transformer/model.tf')\n",
    "\n",
    "        with open('../models/model_general_transformer/maxlen.pickle', 'rb') as handle:\n",
    "            max_len = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_general_transformer/tags.pickle', 'rb') as handle:\n",
    "            tags = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_general_transformer/words.pickle', 'rb') as handle:\n",
    "            word2idx = pickle.load(handle)\n",
    "        \n",
    "        return model, tags, word2idx, max_len\n",
    "    else:\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca0d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_words2idx(text, word2idx, max_len, endpad_idx):\n",
    "    # Convert the tokens to integer IDs using the word2id dictionary\n",
    "    idxs = []\n",
    "    array = []\n",
    "    for token in text:\n",
    "        if token in word2idx.keys():\n",
    "            array.append(word2idx[token])\n",
    "        else:\n",
    "            array.append(0)\n",
    "\n",
    "    while len(array) < max_len:\n",
    "        array.append(endpad_idx)\n",
    "    idxs.append(array)\n",
    "\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74084610",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1918dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents will be split into sentences for easier processing\n",
    "def process_file(file, filename, texts):\n",
    "    content = file.read(filename)\n",
    "    if type(content) == bytes:\n",
    "        text = content.decode('utf-8')\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        for sentence in sentences:\n",
    "            texts.append(sentence)\n",
    "\n",
    "    if len(content.strip()) == 0:\n",
    "        print(\"No text was found\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46cd9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(docs):\n",
    "    # simple preprocessing that removes stopwords and punctuation\n",
    "    sp = WhiteSpacePreprocessingStopwords(docs, min_words=3, stopwords_list=custom_stopwords)\n",
    "\n",
    "    # this function returns the pre and the unpre processed documents and a vocab with the most frequent 2K tokens\n",
    "    # these tokens are going to be used to represent the topics\n",
    "    preprocessed_documents, unpreprocessed_documents, vocab, retained_indices = sp.preprocess() \n",
    "    return preprocessed_documents, vocab, retained_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d46d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(texts, model, tags, word2idx, max_len, ignored_entities, max_texts):\n",
    "    # init variables\n",
    "    ents = []\n",
    "    labels = []\n",
    "    idxs = []\n",
    "    \n",
    "    if ignored_entities:\n",
    "        pattern_string = \".*-(\" + \"|\".join(ignored_entities) + \")|Other|O\"\n",
    "    else:\n",
    "        pattern_string = \"Other|O\"\n",
    "    pattern = re.compile(pattern_string)\n",
    "    endpad_idx = word2idx['endpad']\n",
    "    \n",
    "    for text in texts[:max_texts]:\n",
    "        # transform words to idx to be processed by NER \n",
    "        idxs.append(ner_words2idx(text, word2idx, max_len, endpad_idx)[0])\n",
    "\n",
    "    # predict label, and add to the found entities list\n",
    "    p = model.predict(np.array(idxs), verbose=0)\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for text_idx, text in enumerate(texts[0:max_texts]):\n",
    "        for idx, pred in enumerate(p[text_idx][0:max_texts]):\n",
    "            # add named entity to the entities list if is not endpad and is not ignored\n",
    "            if not pattern.match(tags[pred]):\n",
    "                ents.append(text[idx].lower())\n",
    "                labels.append(tags[pred])\n",
    "        \n",
    "#     ents = remove_stopwords(ents)\n",
    "    return ents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "043a2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_named_entity_clusters(entities, labels):\n",
    "    \n",
    "    # removes 'B-' and 'I-' prefix from entity labels\n",
    "    def remove_prefix(label):\n",
    "        return label.split('-')[-1]\n",
    "\n",
    "    entity_clusters = {}\n",
    "    for entity, label in zip(entities, labels):\n",
    "        if (general_label := remove_prefix(label)) in entity_clusters.keys():\n",
    "            entity_clusters[general_label].append(entity)\n",
    "        else:\n",
    "            entity_clusters[general_label] = [entity]\n",
    "    \n",
    "    # delete small clusters with less than 10 words\n",
    "    for key in entity_clusters.keys():\n",
    "        if len(entity_clusters[key]) < 10:\n",
    "            entity_clusters[key] = []\n",
    "            \n",
    "    return entity_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452abc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_files_from_zip(arch_path, ner_model_mode, ignored_entities=[], max_texts=0):\n",
    "    texts = []\n",
    "    \n",
    "    with zipfile.ZipFile(arch_path, \"r\") as f:\n",
    "        total_f = len(f.namelist())\n",
    "        counter = 1\n",
    "        for filename in f.namelist():\n",
    "            counter += 1\n",
    "            process_file(f, filename, texts)\n",
    "        f.close()\n",
    "        \n",
    "    if texts:\n",
    "        processed_docs, vocab, idxs = process_docs(texts)\n",
    "        tokenized_docs = [nltk.word_tokenize(sentence) for sentence in processed_docs]\n",
    "        # limit observed documents if number is provided as argument\n",
    "        max_texts = len(tokenized_docs) if not max_texts else max_texts\n",
    "        ner, tags, word2idx, max_len = load_ner(ner_model_mode)\n",
    "        # change keys in the NER dictionary to lowercase\n",
    "        word2idx_lowercase = {key.lower(): value for key, value in word2idx.items() if type(key) == str}\n",
    "        if ner:\n",
    "            ents, labels = extract_named_entities(tokenized_docs, ner, tags, word2idx_lowercase, max_len, ignored_entities, max_texts)\n",
    "            \n",
    "            # create a dictionary mapping named entities to integer ids\n",
    "            dictionary = Dictionary(tokenized_docs)\n",
    "\n",
    "            # create a document-term matrix where each document is a text and each term is a named entity\n",
    "            corpus = [dictionary.doc2bow(text) for text in tokenized_docs[:max_texts]]\n",
    "            \n",
    "            # create named entity clusters\n",
    "            entity_clusters = create_named_entity_clusters(ents, labels)\n",
    "            \n",
    "        return corpus, dictionary, entity_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5ab9b",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4bac42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data available:\n",
    "#     - articles_2021-11-05_1000.zip\n",
    "#     - articles_2023-02-09_1000.zip\n",
    "#     - articles_2023-02-04_500.zip\n",
    "ignored_labels = [\"MONEY\", \"QUANTITY\", \"PERCENT\", \"ORDINAL\", \"DATE\", \"TIME\",  \"CARDINAL\"]\n",
    "\n",
    "corpus, dictionary, entity_clusters = preprocess_files_from_zip(\n",
    "    \"../data/articles_2021-11-05_1000.zip\", \n",
    "    \"general_transformer\", \n",
    "    ignored_labels,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846988f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_clusters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848bec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplier per label: 0.16666666666666666\n",
      "10000 18330\n"
     ]
    }
   ],
   "source": [
    "# create artificial documents from named entities and add them to corpus\n",
    "corpus_extended = copy.deepcopy(corpus)\n",
    "corpus_len = len(corpus)\n",
    "\n",
    "# coefficient used to determine number of artificial articles per label relative to the size of corpus (number of texts)\n",
    "multiplication_coef = 1/len(entity_clusters.keys())\n",
    "print(\"multiplier per label: \" + str(multiplication_coef))\n",
    "\n",
    "# add named entities to dictionary and corpus\n",
    "for entity_type, entities in entity_clusters.items():\n",
    "    if len(entities) > 5:\n",
    "        processed_ents = [entity.lower() for entity in set(entities)]\n",
    "        new_doc = [dictionary.doc2bow(simple_preprocess(entity)) for entity in processed_ents]\n",
    "        new_doc = [item for entity in new_doc for item in entity]\n",
    "        for i in range(int(corpus_len*multiplication_coef)):\n",
    "            corpus_extended.append(new_doc)\n",
    "\n",
    "print(len(corpus), len(corpus_extended))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621eaa9",
   "metadata": {},
   "source": [
    "## LDA and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40239f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda(corpus, num_topics):\n",
    "    # Create the LDA model\n",
    "    lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                id2word=dictionary,\n",
    "                                num_topics=num_topics,\n",
    "                                workers=19,\n",
    "                                random_state=100,\n",
    "                                chunksize=100,\n",
    "                                passes=10,\n",
    "                                iterations=200,\n",
    "                                alpha='symmetric',\n",
    "                                per_word_topics=False\n",
    "                                )\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e6e62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nmf(corpus, num_topics):\n",
    "    # Create the NMF model\n",
    "    nmf_model = Nmf(corpus=corpus,\n",
    "                    id2word=dictionary,\n",
    "                    num_topics=num_topics,\n",
    "                    random_state=100,\n",
    "                    chunksize=100,\n",
    "                    passes=10,\n",
    "                    normalize=True\n",
    "                    )\n",
    "    return nmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045fbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def calc_hausdorff_distance(model):\n",
    "    num_topics = model.num_topics\n",
    "    hd_matrix = np.zeros((num_topics, num_topics))  # Initialize a matrix to store HD values\n",
    "    \n",
    "    for i in range(num_topics):\n",
    "        for j in range(i+1, num_topics):\n",
    "            # extract topic distributions for topics i and j\n",
    "            topic_i_dist = np.array([[p] for _, p in model.get_topic_terms(i)])\n",
    "            topic_j_dist = np.array([[p] for _, p in model.get_topic_terms(j)])\n",
    "\n",
    "            # compute asymmetric Hausdorff distance (HD) by saving the biggest of the two\n",
    "            hd = max(distance.directed_hausdorff(topic_i_dist, topic_j_dist), \n",
    "                      distance.directed_hausdorff(topic_j_dist, topic_i_dist))\n",
    "\n",
    "            hd_matrix[i, j] = hd[0]\n",
    "\n",
    "    return np.mean(hd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e729e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_tus(model):\n",
    "    \"\"\"\n",
    "    Calculate Topic Uniqueness Score (TUS) for each topic in a given LDA model.\n",
    "    Returns an array of TUS scores and a mean TUS score for a model.\n",
    "    The lower TUS score means that topics are less similar <-> more unique.\n",
    "    \"\"\"\n",
    "    words_num = len(model.id2word)\n",
    "#     words_num = 1800\n",
    "    num_topics = model.num_topics\n",
    "    word_probs = np.zeros((num_topics, words_num))\n",
    "    for topic_id in range(num_topics):\n",
    "        word_probs[topic_id, :] = np.array([p for _, p in model.get_topic_terms(topic_id, words_num)])\n",
    "    \n",
    "    similarities = cosine_similarity(word_probs)\n",
    "    np.fill_diagonal(similarities, 0) # set diagonal to 0 so a topic is not compared with itself\n",
    "    tus_scores = np.mean(similarities, axis=1)\n",
    "    tus_mean = np.mean(tus_scores)\n",
    "    return tus_scores, tus_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94b1b600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress: [████████████████████████████████████████████████████████████████████████████████████████████████████] 100.00%\n"
     ]
    }
   ],
   "source": [
    "results = {'tus': {}, 'hd': {}}\n",
    "corpuses = {\"classic corpus\": corpus, \"extended corpus\": corpus_extended}\n",
    "num_topics_arr = [5, 10, 15, 20]\n",
    "\n",
    "def do_test(use_lda = True):\n",
    "    total_iter = len(corpuses) * len(num_topics_arr)\n",
    "    curr_iter = 1\n",
    "    for key in corpuses:\n",
    "        results['tus'][key] = {}\n",
    "        results['hd'][key] = {}\n",
    "        for num_topics in num_topics_arr:\n",
    "            progress_bar(curr_iter, total_iter)\n",
    "            if use_lda:\n",
    "                lda_model = train_lda(corpuses[key], num_topics)\n",
    "                _, score_tus = calculate_tus(lda_model)\n",
    "                score_hd = calc_hausdorff_distance(lda_model)\n",
    "            else:\n",
    "                nmf_model = train_nmf(corpuses[key], num_topics)\n",
    "                _, score_tus = calculate_tus(nmf_model)\n",
    "                score_hd = calc_hausdorff_distance(nmf_model)\n",
    "            \n",
    "            results['tus'][key][str(num_topics)] = score_tus\n",
    "            results['hd'][key][str(num_topics)] = score_hd\n",
    "            curr_iter += 1\n",
    "\n",
    "# test_tus = True\n",
    "use_lda = False\n",
    "do_test(use_lda)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06646827",
   "metadata": {},
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ff024",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fa7b74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classic_keys = list(results['tus']['classic corpus'].keys())\n",
    "extended_keys = list(results['tus']['extended corpus'].keys())\n",
    "\n",
    "classic_values = list(results['tus']['classic corpus'].values())\n",
    "extended_values = list(results['tus']['extended corpus'].values())\n",
    "\n",
    "x_values = range(len(classic_keys))\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "model_string = \"LDA\" if use_lda else \"NMF\"\n",
    "\n",
    "# plot the bars for the classic dictionary values\n",
    "plt.bar(x_values, classic_values, align='edge', width=-bar_width, alpha=1, label=f'Classic {model_string}')\n",
    "\n",
    "# plot the bars for the new dictionary values\n",
    "plt.bar(x_values, extended_values, align='edge', width=bar_width, alpha=1, label=f'NER + {model_string}')\n",
    "\n",
    "# set the x-axis ticks and labels\n",
    "plt.xticks(x_values, classic_keys)\n",
    "\n",
    "# add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "Y_str = \"TUS\"\n",
    "\n",
    "# set the y-axis label\n",
    "plt.ylabel(Y_str)\n",
    "\n",
    "# set the x-axis label\n",
    "plt.xlabel('Number of topics')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f0d7ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classic_keys = list(results['hd']['classic corpus'].keys())\n",
    "extended_keys = list(results['hd']['extended corpus'].keys())\n",
    "\n",
    "classic_values = list(results['hd']['classic corpus'].values())\n",
    "extended_values = list(results['hd']['extended corpus'].values())\n",
    "\n",
    "x_values = range(len(classic_keys))\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "model_string = \"LDA\" if use_lda else \"NMF\"\n",
    "\n",
    "# plot the bars for the classic dictionary values\n",
    "plt.bar(x_values, classic_values, align='edge', width=-bar_width, alpha=1, label=f'Classic {model_string}')\n",
    "\n",
    "# plot the bars for the new dictionary values\n",
    "plt.bar(x_values, extended_values, align='edge', width=bar_width, alpha=1, label=f'NER + {model_string}')\n",
    "\n",
    "# set the x-axis ticks and labels\n",
    "plt.xticks(x_values, classic_keys)\n",
    "\n",
    "# add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "Y_str = \"Hausdorff Distance\" \n",
    "\n",
    "# set the y-axis label\n",
    "plt.ylabel(Y_str)\n",
    "\n",
    "# set the x-axis label\n",
    "plt.xlabel('Number of topics')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb598d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

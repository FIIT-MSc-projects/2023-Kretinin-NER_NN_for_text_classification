{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fff8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel, Nmf\n",
    "from gensim.utils import simple_preprocess\n",
    "import zipfile\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras import layers\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import tqdm\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
    "import copy\n",
    "\n",
    "# WIP code part\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# nltk.download('en_core_web_sm')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# load the pre-trained English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "custom_stopwords = set(stopwords.words(\"english\"))\n",
    "custom_stopwords = custom_stopwords.union({\"reuters\", \"bbc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1186c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same one as in the test_environment.py\n",
    "def progress_bar(iteration, total):\n",
    "    total_len = 100\n",
    "    percent_part = (\"{0:.2f}\").format(100 * (iteration / total))\n",
    "    filled = int(total_len * iteration / total)\n",
    "    bar = 'â–ˆ' * filled + '-' * (total_len - filled)\n",
    "    print(f'\\r Progress: [{bar}] {percent_part}%', end='')\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4150b",
   "metadata": {},
   "source": [
    "## NER functions and architecture (transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d668ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        query = tf.reshape(\n",
    "            tf.transpose(tf.reshape(query, (batch_size, -1, self.num_heads, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size * self.num_heads, -1, self.head_dim),\n",
    "        )\n",
    "        key = tf.reshape(\n",
    "            tf.transpose(tf.reshape(key, (batch_size, -1, self.num_heads, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size * self.num_heads, -1, self.head_dim),\n",
    "        )\n",
    "        value = tf.reshape(\n",
    "            tf.transpose(tf.reshape(value, (batch_size, -1, self.num_heads, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size * self.num_heads, -1, self.head_dim),\n",
    "        )\n",
    "\n",
    "        attention_logits = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_logits = attention_logits / tf.math.sqrt(tf.cast(self.head_dim, tf.float32))\n",
    "        attention_weights = tf.nn.softmax(attention_logits, axis=-1)\n",
    "\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        output = tf.reshape(\n",
    "            tf.transpose(tf.reshape(output, (batch_size, self.num_heads, -1, self.head_dim)), perm=[0, 2, 1, 3]),\n",
    "            (batch_size, -1, self.embed_dim),\n",
    "        )\n",
    "        output = self.combine_heads(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1518912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                keras.layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        ffn_output = self.ffn(attn_output)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(inputs + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82328b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        maxlen = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        position_embeddings = self.pos_emb(positions)\n",
    "        token_embeddings = self.token_emb(inputs)\n",
    "        return token_embeddings + position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f80fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(keras.Model):\n",
    "    def __init__(\n",
    "        self, num_tags, vocab_size, maxlen=128, embed_dim=32, num_heads=2, ff_dim=32, num_layers=1, rate=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "#         self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.transformer_blocks = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n",
    "        self.dropout1 = layers.Dropout(0.1)\n",
    "        self.ff = layers.Dense(ff_dim, activation=\"relu\")\n",
    "        self.ff_final = layers.Dense(num_tags, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.ff(x)\n",
    "        x = self.ff_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a72977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_model_mode: model we want to use\n",
    "#     - specific_lstm: BiLSTM model trained on CORD19 data\n",
    "#     - general_lstm: BiLSTM model trained on general (topics) data\n",
    "#     - specific_transformer: Transformer-based model trained on CORD19 data\n",
    "#     - general_transformer:Transformer-based model trained on general (topics) data\n",
    "def load_ner(ner_model_mode):\n",
    "    if ner_model_mode == \"specific_lstm\":\n",
    "        pass\n",
    "    elif ner_model_mode == \"general_lstm\":\n",
    "        pass\n",
    "    elif ner_model_mode == \"specific_transformer\":\n",
    "        model = keras.models.load_model('../models/model_cord_transformer/model.tf')\n",
    "\n",
    "        with open('../models/model_cord_transformer/maxlen.pickle', 'rb') as handle:\n",
    "            max_len = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_cord_transformer/tags.pickle', 'rb') as handle:\n",
    "            tags = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_cord_transformer/words.pickle', 'rb') as handle:\n",
    "            word2idx = pickle.load(handle)\n",
    "        \n",
    "        return model, tags, word2idx, max_len\n",
    "    elif ner_model_mode == \"general_transformer\":\n",
    "        model = keras.models.load_model('../models/model_general_transformer/model.tf')\n",
    "\n",
    "        with open('../models/model_general_transformer/maxlen.pickle', 'rb') as handle:\n",
    "            max_len = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_general_transformer/tags.pickle', 'rb') as handle:\n",
    "            tags = pickle.load(handle)\n",
    "\n",
    "        with open('../models/model_general_transformer/words.pickle', 'rb') as handle:\n",
    "            word2idx = pickle.load(handle)\n",
    "        \n",
    "        return model, tags, word2idx, max_len\n",
    "    else:\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca0d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_words2idx(text, word2idx, max_len, endpad_idx):\n",
    "    # Convert the tokens to integer IDs using the word2id dictionary\n",
    "    idxs = []\n",
    "    array = []\n",
    "    for token in text:\n",
    "        if token in word2idx.keys():\n",
    "            array.append(word2idx[token])\n",
    "        else:\n",
    "            array.append(0)\n",
    "\n",
    "    while len(array) < max_len:\n",
    "        array.append(endpad_idx)\n",
    "    idxs.append(array)\n",
    "\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74084610",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1918dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents will be split into sentences for easier processing\n",
    "def process_file(file, filename, texts):\n",
    "    content = file.read(filename)\n",
    "    if type(content) == bytes:\n",
    "        text = content.decode('utf-8')\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        for sentence in sentences:\n",
    "            texts.append(sentence)\n",
    "\n",
    "    if len(content.strip()) == 0:\n",
    "        print(\"No text was found\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46cd9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(docs):\n",
    "    # simple preprocessing that removes stopwords and punctuation\n",
    "    sp = WhiteSpacePreprocessingStopwords(docs, min_words=3, stopwords_list=custom_stopwords)\n",
    "\n",
    "    # this function returns the pre and the unpre processed documents and a vocab with the most frequent 2K tokens\n",
    "    # these tokens are going to be used to represent the topics\n",
    "    preprocessed_documents, unpreprocessed_documents, vocab, retained_indices = sp.preprocess() \n",
    "    return preprocessed_documents, vocab, retained_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d46d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(texts, model, tags, word2idx, max_len, ignored_entities, max_texts):\n",
    "    # init variables\n",
    "    ents = []\n",
    "    labels = []\n",
    "    idxs = []\n",
    "    \n",
    "    if ignored_entities:\n",
    "        pattern_string = \".*-(\" + \"|\".join(ignored_entities) + \")|Other|O\"\n",
    "    else:\n",
    "        pattern_string = \"Other|O\"\n",
    "    pattern = re.compile(pattern_string)\n",
    "    endpad_idx = word2idx['endpad']\n",
    "    \n",
    "    for text in texts[:max_texts]:\n",
    "        # transform words to idx to be processed by NER \n",
    "        idxs.append(ner_words2idx(text, word2idx, max_len, endpad_idx)[0])\n",
    "\n",
    "    # predict label, and add to the found entities list\n",
    "    p = model.predict(np.array(idxs), verbose=0)\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for text_idx, text in enumerate(texts[0:max_texts]):\n",
    "        for idx, pred in enumerate(p[text_idx][0:max_texts]):\n",
    "            # add named entity to the entities list if is not endpad and is not ignored\n",
    "            if not pattern.match(tags[pred]):\n",
    "                ents.append(text[idx].lower())\n",
    "                labels.append(tags[pred])\n",
    "        \n",
    "#     ents = remove_stopwords(ents)\n",
    "    return ents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "043a2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_named_entity_clusters(entities, labels):\n",
    "    \n",
    "    # removes 'B-' and 'I-' prefix from entity labels\n",
    "    def remove_prefix(label):\n",
    "        return label.split('-')[-1]\n",
    "\n",
    "    entity_clusters = {}\n",
    "    for entity, label in zip(entities, labels):\n",
    "        if (general_label := remove_prefix(label)) in entity_clusters.keys():\n",
    "            entity_clusters[general_label].append(entity)\n",
    "        else:\n",
    "            entity_clusters[general_label] = [entity]\n",
    "    \n",
    "    # delete small clusters with less than 10 words\n",
    "    for key in entity_clusters.keys():\n",
    "        if len(entity_clusters[key]) < 10:\n",
    "            entity_clusters[key] = []\n",
    "            \n",
    "    return entity_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452abc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_files_from_zip(arch_path, ner_model_mode, ignored_entities=[], max_texts=0):\n",
    "    texts = []\n",
    "    \n",
    "    with zipfile.ZipFile(arch_path, \"r\") as f:\n",
    "        total_f = len(f.namelist())\n",
    "        counter = 1\n",
    "        for filename in f.namelist():\n",
    "            counter += 1\n",
    "            process_file(f, filename, texts)\n",
    "        f.close()\n",
    "        \n",
    "    if texts:\n",
    "        processed_docs, vocab, idxs = process_docs(texts)\n",
    "        tokenized_docs = [nltk.word_tokenize(sentence) for sentence in processed_docs]\n",
    "        # limit observed documents if number is provided as argument\n",
    "        max_texts = len(tokenized_docs) if not max_texts else max_texts\n",
    "        ner, tags, word2idx, max_len = load_ner(ner_model_mode)\n",
    "        # change keys in the NER dictionary to lowercase\n",
    "        word2idx_lowercase = {key.lower(): value for key, value in word2idx.items() if type(key) == str}\n",
    "        if ner:\n",
    "            ents, labels = extract_named_entities(tokenized_docs, ner, tags, word2idx_lowercase, max_len, ignored_entities, max_texts)\n",
    "            \n",
    "            # create a dictionary mapping named entities to integer ids\n",
    "            dictionary = Dictionary(tokenized_docs)\n",
    "\n",
    "            # create a document-term matrix where each document is a text and each term is a named entity\n",
    "            corpus = [dictionary.doc2bow(text) for text in tokenized_docs[:max_texts]]\n",
    "            \n",
    "            # create named entity clusters\n",
    "            entity_clusters = create_named_entity_clusters(ents, labels)\n",
    "            \n",
    "        return corpus, dictionary, entity_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5ab9b",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4bac42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data available:\n",
    "#     - articles_2021-11-05_1000.zip\n",
    "#     - articles_2023-02-09_1000.zip\n",
    "#     - articles_2023-02-04_500.zip\n",
    "ignored_labels = [\"MONEY\", \"QUANTITY\", \"PERCENT\", \"ORDINAL\", \"DATE\", \"TIME\",  \"CARDINAL\"]\n",
    "\n",
    "corpus, dictionary, entity_clusters = preprocess_files_from_zip(\n",
    "    \"../data/articles_2021-11-05_1000.zip\", \n",
    "    \"general_transformer\", \n",
    "    ignored_labels,\n",
    "    3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846988f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_clusters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848bec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplier per label: 0.1\n",
      "3000 4500\n"
     ]
    }
   ],
   "source": [
    "# create artificial documents from named entities and add them to corpus\n",
    "corpus_extended = copy.deepcopy(corpus)\n",
    "corpus_len = len(corpus)\n",
    "\n",
    "# coefficient used to determine number of artificial articles per label relative to the size of corpus (number of texts)\n",
    "multiplication_coef = 0.5/len(entity_clusters.keys())\n",
    "print(\"multiplier per label: \" + str(multiplication_coef))\n",
    "\n",
    "# add named entities to dictionary and corpus\n",
    "for entity_type, entities in entity_clusters.items():\n",
    "    if len(entities) > 5:\n",
    "        processed_ents = [entity.lower() for entity in set(entities)]\n",
    "        new_doc = [dictionary.doc2bow(simple_preprocess(entity)) for entity in processed_ents]\n",
    "        new_doc = [item for entity in new_doc for item in entity]\n",
    "        for i in range(int(corpus_len*multiplication_coef)):\n",
    "            corpus_extended.append(new_doc)\n",
    "\n",
    "print(len(corpus), len(corpus_extended))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621eaa9",
   "metadata": {},
   "source": [
    "## LDA and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40239f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda(corpus, num_topics):\n",
    "    # Create the LDA model\n",
    "    lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                id2word=dictionary,\n",
    "                                num_topics=num_topics,\n",
    "                                workers=19,\n",
    "                                random_state=100,\n",
    "                                chunksize=100,\n",
    "                                passes=10,\n",
    "                                iterations=200,\n",
    "                                alpha='symmetric',\n",
    "                                per_word_topics=False\n",
    "                                )\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e6e62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nmf(corpus, num_topics):\n",
    "    # Create the NMF model\n",
    "    nmf_model = Nmf(corpus=corpus,\n",
    "                    id2word=dictionary,\n",
    "                    num_topics=num_topics,\n",
    "                    random_state=100,\n",
    "                    chunksize=100,\n",
    "                    passes=10,\n",
    "                    normalize=True\n",
    "                    )\n",
    "    return nmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045fbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def calc_hausdorff_distance(model):\n",
    "    num_topics = model.num_topics\n",
    "    hd_matrix = np.zeros((num_topics, num_topics))  # Initialize a matrix to store HD values\n",
    "    \n",
    "    for i in range(num_topics):\n",
    "        for j in range(i+1, num_topics):\n",
    "            # extract topic distributions for topics i and j\n",
    "            topic_i_dist = np.array([[p] for _, p in model.get_topic_terms(i)])\n",
    "            topic_j_dist = np.array([[p] for _, p in model.get_topic_terms(j)])\n",
    "\n",
    "            # compute asymmetric Hausdorff distance (HD) by saving the biggest of the two\n",
    "            hd = max(distance.directed_hausdorff(topic_i_dist, topic_j_dist), \n",
    "                      distance.directed_hausdorff(topic_j_dist, topic_i_dist))\n",
    "\n",
    "            hd_matrix[i, j] = hd[0]\n",
    "\n",
    "    return np.mean(hd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a9f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def calc_jansen_shannon_divergence(model):\n",
    "    num_topics = model.num_topics\n",
    "    js_matrix = np.zeros((num_topics, num_topics))  # Initialize a matrix to store JS values\n",
    "    \n",
    "    for i in range(num_topics):\n",
    "        for j in range(i+1, num_topics):\n",
    "            # extract topic distributions for topics i and j\n",
    "            topic_i_dist = np.array([[p] for _, p in model.get_topic_terms(i)])\n",
    "            topic_j_dist = np.array([[p] for _, p in model.get_topic_terms(j)])\n",
    "\n",
    "            js_divergence = jensenshannon(topic_i_dist, topic_j_dist)\n",
    "\n",
    "            js_matrix[i, j] = js_divergence\n",
    "\n",
    "    return np.mean(js_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e729e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_tus(model):\n",
    "    \"\"\"\n",
    "    Calculate Topic Uniqueness Score (TUS) for each topic in a given LDA model.\n",
    "    Returns an array of TUS scores and a mean TUS score for a model.\n",
    "    The lower TUS score means that topics are less similar <-> more unique.\n",
    "    \"\"\"\n",
    "    words_num = len(model.id2word)\n",
    "#     words_num = 1800\n",
    "    num_topics = model.num_topics\n",
    "    word_probs = np.zeros((num_topics, words_num))\n",
    "    for topic_id in range(num_topics):\n",
    "        word_probs[topic_id, :] = np.array([p for _, p in model.get_topic_terms(topic_id, words_num)])\n",
    "    \n",
    "    similarities = cosine_similarity(word_probs)\n",
    "    np.fill_diagonal(similarities, 0) # set diagonal to 0 so a topic is not compared with itself\n",
    "    tus_scores = np.mean(similarities, axis=1)\n",
    "    tus_mean = np.mean(tus_scores)\n",
    "    return tus_scores, tus_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94b1b600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.00%\n"
     ]
    }
   ],
   "source": [
    "results = {'tus': {}, 'js': {}}\n",
    "corpuses = {\"classic corpus\": corpus, \"extended corpus\": corpus_extended}\n",
    "num_topics_arr = [5, 10, 15, 20]\n",
    "\n",
    "def do_test(use_lda = True):\n",
    "    total_iter = len(corpuses) * len(num_topics_arr)\n",
    "    curr_iter = 1\n",
    "    for key in corpuses:\n",
    "        results['tus'][key] = {}\n",
    "        results['js'][key] = {}\n",
    "        for num_topics in num_topics_arr:\n",
    "            progress_bar(curr_iter, total_iter)\n",
    "            if use_lda:\n",
    "                lda_model = train_lda(corpuses[key], num_topics)\n",
    "                _, score_tus = calculate_tus(lda_model)\n",
    "                score_hd = calc_hausdorff_distance(lda_model)\n",
    "                score_js = calc_jansen_shannon_divergence(lda_model)\n",
    "            else:\n",
    "                nmf_model = train_nmf(corpuses[key], num_topics)\n",
    "                _, score_tus = calculate_tus(nmf_model)\n",
    "                score_hd = calc_hausdorff_distance(nmf_model)\n",
    "                score_js = calc_jansen_shannon_divergence(nmf_model)\n",
    "            \n",
    "            results['tus'][key][str(num_topics)] = score_tus\n",
    "            results['js'][key][str(num_topics)] = score_js\n",
    "            curr_iter += 1\n",
    "\n",
    "# test_tus = True\n",
    "use_lda = False\n",
    "do_test(use_lda)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06646827",
   "metadata": {},
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ff024",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fa7b74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcIUlEQVR4nO3de5xVdb3/8dfbEYQSNWE0YxDGxBQ1RQfMy/GGlpgPLG9AcZLUUBMNb0fywvGQ/hL5ZdrvRyaa6dEU0ETHI4Zm4LG8NGOScokiRB1SmMi8JBeBz/ljLzibPXsGhtlrhpn1fj4e85i9vuu71/rMeuzHvPe6fZciAjMzy67t2roAMzNrWw4CM7OMcxCYmWWcg8DMLOMcBGZmGbd9WxfQXD169Ig+ffq0dRlmZu3Kyy+//LeIKC82r90FQZ8+faitrW3rMszM2hVJbzQ2z4eGzMwyzkFgZpZxDgIzs4xrd+cIzGzb9/HHH1NXV8eqVavaupTM6dKlCxUVFXTq1GmL3+MgMLOSq6uro1u3bvTp0wdJbV1OZkQEK1asoK6ujsrKyi1+nw8NmVnJrVq1iu7duzsEWpkkunfv3uw9MQeBmaXCIdA2tma7OwjMzDLO5wjMLHV9xj5R0uUtuenLm+3zzjvvMGbMGGpqathll13YfffdufXWW+ncuTOnnHIKc+fOLUkt48aN4+ijj+aEE07YbN8lS5ZQWVnJj370Iy6++GIARo8eTVVVFSNHjmTkyJFMmzaNZcuW0a1bNwDGjBnDbbfdRn19PT169KCsrIwDDzxw4zIfffRRWjragoPAzDqciOCrX/0qZ599Nlf/358AsHD+azz/2iJ2/0wFqz5ex6t1/yjJus4YdRmfr9hli/vvtttu3HbbbZx//vl07ty5wfy9996bxx57jBEjRrB+/Xp+/etf07Nnz43zu3btypw5c0pQ+f/yoSEz63BmzZpFp06duOCCCza2fa7fgRxy2BGb9Fv61puMPG0wQwcfw9DBxzCn9iUA6pe9wzdPP5mzvvQvnDbocH7/0vOsW7eO6y79NqcNOpzTTziC++78MQDXXfptHn74YQBqamo44ogjOOiggxg4cCAffPBBg9rKy8sZNGgQ9957b9Hahw0bxtSpUwGYPXs2Rx55JNtvn+53du8RmFmHM3fuXA499NDN9tu1Rw/ueGA6O3Tpwhuv/4WxF53HgzNmMePRhznimOP51iVXsG7dOlat/IiF815j+bK3eeSZFwB4/733NlnWmjVrGDp0KFOnTmXAgAG8//77dO3ateh6r7rqKgYPHsw555zTYN4+++xDdXU17777Lg8++CAjRozgySef3Dh/5cqVHHzwwQBUVlYyffr0Ld0sjXIQmFlmrf34Y75/3b+xcN5rlJWV8cbivwBwwEH9+fcrLmbt2rUc96Uvs+/+B1KxZx/q3ljC96/7N44+/oscfszxmyxr4cKF7LHHHgwYMACAnXbaqdH17rXXXhx22GE88MADReefdtppTJkyhZdeeok77rhjk3k+NGRmtgX2339/Xn755c32u/+u2+neYzceeuo3PPDELD7+eA0Ah37hSO5++Al2+/QejLvs2zz+8BR22mUXHnrqOQYcfhQP3f8zrr/ykhbVePXVVzNhwgQiosG8oUOHct1113HiiSey3Xbp/5v2HoHZNqTUV9c0ZkuuumnPjj/+eK6++momT57MF04+C4A/LZjLh++/z+6fqdjY78P332e3PT7DdtttR/VDD7Ju3ToA/lr3Jrvv0ZPTv3Y2a9asZsHcP3DU8SfSqVMnTjh5CL332ptrvnP+Juv83Oc+x9tvv01NTQ0DBgzggw8+oGvXro0e3993333p168fjz/++Ma9iA169+7NjTfeuEVXIpVCqkEg6STgNqAMuCsibiqYvydwL7BL0mdsRMxIsyYza32tHTySmD59OmPGjOF7N36fzl260LOiF1de//1N+p119rlcPuob/NcvpnDEsYPo+olPAlD7wm+55yc/YvtOnfjEJz7JDbf+hOXv/JVxl48m1q8H4JKx4zZZVufOnZk6dSoXX3wxK1eupGvXrvzqV79ixx13bLTOa665hv79+xedd/755xdtT4OK7ZaUZMFSGfAn4ESgDqgBhkfE/Lw+k4FXIuJ2Sf2AGRHRp6nlVlVVhR9MYx1VR9kjWLBgAfvtt1+q69hSpbpMtCnNuXy0NRTb/pJejoiqYv3TPPg0EFgUEYsjYg0wBTi1oE8AG86o7Az8NcV6zMysiDSDoCfwVt50XdKW73pghKQ6YAZwcbEFSRolqVZSbX19fRq1mpllVltfNTQcuCciKoCTgfskNagpIiZHRFVEVJWXF332spmZbaU0g2Ap0CtvuiJpy3cuMA0gIl4AugA9UqzJzMwKpBkENUBfSZWSOgPDgOqCPm8CgwAk7UcuCHzsx8ysFaUWBBGxFhgNzAQWANMiYp6k8ZKGJN0uB74l6Q/Ag8DISOsyJjMzKyrV+wiSewJmFLSNy3s9HzgyzRrMbBtw/c4lXt57m+0iicsuu4yzL70OgHt/8v/46KN/cuFlY7n9lpv4xQP/ya7du2/sf9e0/2Lh/NcYc+7X6NmrN6tXr+boQV/i8uu+1+Jyjz32WD788EM2XPpeW1vLFVdcwezZs5k9ezbHHXccd955J+eddx4Ac+bMoX///kycOJErrriCkSNH8uyzz7LzzrnteM4553DJJS27szlfW58sNjNLxQ477MAjjzzCu39fUXT+v553IdNmPrfxZ6fkn2z/gYczbeZzTH3yWf77mZm8UvNik+u5/ZabuOeeezZbz/LlyzcZPC7fAQccwLRp0zZOP/jggxx00EGb9Jk4cSJz5sxhzpw5JQ0BcBCYWQe1/fbbM2rUKO5Photuri5du/K5fgew/J23S1LPlVdeyY033lh0Xu/evVm1ahXLli0jIvjlL3/J4MGDS7LeLeGxhqxFWuNO2I4+Lo6l56KLLmK//Q9g5IUNv0Hfd9ftPDE99y2828678NNpj28y//1//IM3lyzm0IJnGGytww8/nOnTpzNr1qyNTx/Ld8YZZ/DQQw/Rv39/DjnkEHbYYYdN5l955ZXccMMNudrvu2+Tp5S1lIPAzDqsnXbaiVNOH8YDd0+mS5cum8z71/Mu5OwLGt7D+srvXuDMLx7Fm68v5uvnXkCP3XZv0OfPC+ZxzZjcQ2/+Vr+cJ7rswK233grAM888Q/e8cw/5rr32Wm644QYmTJjQYN5ZZ53F0KFD+eMf/8jw4cN5/vnnN5k/ceJEzjjjjC36u5vLh4bMrEMbce6FPDr1Plau/GiL+vcfeDgPPfUbfvHMC0yfej9/nPdagz5999t/47mFM0d8k/Hjx288ft9YCEBuVNSVK1fy4osNzzt8+tOfplOnTjz99NMMGjRoy//AEnAQmFmHtvOnPsUXT/kK06fc16z3VezZm3O+PYaf/fjWktZz7bXXcvPNNxedN378eCZMmEBZWVlJ17k5PjRkZunbgss90/SNUaOZcs9dm7TlnyMA+OFdP2/wvjNHfJN77/j/LH3rTXr22rMktZx88sk0NlTOEUeU5nxEc6U2DHVaPAz1tsUni0vLw1CXnoehzmmrYajNzKwdcBCYmWWcg8DMUtHeDjt3FFuz3R0EZlZyXbp0YcWKFQ6DVhYRrFixosE9E5vjq4bMrOQqKiqoq6tjW3ii4LJ3V6a+jgUfdE19HVuqS5cuVFRUNOs9DgIzK7lOnTpRWVnZ1mUAMNhXtm2WDw2ZmWWcg8DMLONSDQJJJ0laKGmRpLFF5v9Q0pzk50+S/pFmPWZm1lBq5wgklQGTgBOBOqBGUnXyVDIAIuLSvP4XA/3TqsfMzIpLc49gILAoIhZHxBpgCnBqE/2Hk3tusZmZtaI0g6An8FbedF3S1oCk3kAl8OtG5o+SVCupdlu4HM3MrCPZVk4WDwMejoh1xWZGxOSIqIqIqsZG7TMzs62TZhAsBXrlTVckbcUMw4eFzMzaRJpBUAP0lVQpqTO5f/bVhZ0k7Qt8CnghxVrMzKwRqQVBRKwFRgMzgQXAtIiYJ2m8pCF5XYcBU8KDkpiZtYlUh5iIiBnAjIK2cQXT16dZg5mZNW1bOVlsZmZtxEFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLONSHX10W9Nn7BOtsp4lN325VdZjZlYK3iMwM8s4B4GZWcalGgSSTpK0UNIiSWMb6XOWpPmS5kl6IM16zMysodTOEUgqAyYBJwJ1QI2k6oiYn9enL/Bd4MiIeFfSbmnVY2ZmxaW5RzAQWBQRiyNiDTAFOLWgz7eASRHxLkBELE+xHjMzKyLNIOgJvJU3XZe05dsH2EfSbyW9KOmkYguSNEpSraTa+vr6lMo1M8umtj5ZvD3QFzgWGA7cKWmXwk4RMTkiqiKiqry8vHUrNDPr4NIMgqVAr7zpiqQtXx1QHREfR8TrwJ/IBYOZmbWSNIOgBugrqVJSZ2AYUF3Q51FyewNI6kHuUNHiFGsyM7MCqQVBRKwFRgMzgQXAtIiYJ2m8pCFJt5nACknzgVnAlRGxIq2azMysoVSHmIiIGcCMgrZxea8DuCz56Tiu37kV1vFe+usws0xo65PFZmbWxhwEZmYZ5yAwM8s4B4GZWcY5CMzMMi5TD6Yxs4SvbCut1tiekNo29R6BmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzjfUGbbvnZ+s47Zti7VPQJJJ0laKGmRpLFF5o+UVC9pTvJzXpr1mJlZQ6ntEUgqAyYBJ5J7NnGNpOqImF/QdWpEjE6rDjMza1qaewQDgUURsTgi1gBTgFNTXJ+ZmW2FNIOgJ/BW3nRd0lbodEmvSnpYUq9iC5I0SlKtpNr6+vo0ajUzy6y2vmrocaBPRHweeBq4t1iniJgcEVURUVVeXt6qBZqZdXRpBsFSIP8bfkXStlFErIiI1cnkXcChKdZjZmZFpBkENUBfSZWSOgPDgOr8DpL2yJscAixIsR4zMysitauGImKtpNHATKAMuDsi5kkaD9RGRDVwiaQhwFrg78DItOoxM7PiUr2hLCJmADMK2sblvf4u8N00azAzs6a19cliMzNrY80KAkmfkqS0ijEzs9bXaBBIGidp3+T1DpJmAX8Blkk6obUKNDOzdDW1RzAUWJi8Pjv5XQ4cA/yfNIsyM7PW01QQrImISF5/CZgSEesiYgEetdTMrMNoKghWSzpAUjlwHPBU3rxPpFuWmZm1lqa+2Y8BHiZ3OOiHEfE6gKSTgVfSL83MzFpDo0EQES8C+xZpb3BvgJmZtV+NBoGkywqaAvgb8JsNewdmZtb+NXWOoFvBz05AFfCkpGGtUJuZmbWCpg4N/Uexdkm7Ar8i96AZMzNr55o9xERE/B3w3cVmZh1Es4NA0nHAuynUYmZmbaCpk8VzgfUFzbsCfwW+kWZRZmbWepq6j6AncHDedAArIuKfqVZkZmatqqkgeD0i3mi1SszMrE00FQS7FbmXYKOIuGVzC5d0EnAbuSeU3RURNzXS73RydzEPiIjazS3XzMxKp6kgKAN2ZCuvEJJUBkwCTgTqgBpJ1RExv6BfN+A7wEtbsx4zM2uZpoLg7YgY34JlDwQWRcRiAElTgFOB+QX9vgdMAK5swbrMzGwrNXX5aEvvFegJvJU3XZe0/e8KpEOAXhHxRFMLkjRKUq2k2vr6+haWZWZm+ZoKgkFprljSdsAtwOWb6xsRkyOiKiKqysvL0yzLzCxzGg2C5A7illgK9MqbrkjaNugGHADMlrQE+AJQLamqhes1M7NmaPadxc1QA/SVVCmpMzAMqN4wMyLei4geEdEnIvoALwJDfNWQmVnrSi0IImItMBqYCSwApkXEPEnjJQ1Ja71mZtY8qT57uNhDbCJiXCN9j02zFjMzKy7NQ0NmZtYOOAjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8u4VINA0kmSFkpaJGlskfkXSHpN0hxJv5HUL816zMysodSCQFIZMAkYDPQDhhf5R/9ARBwYEQcDNwO3pFWPmZkVl+YewUBgUUQsjog1wBTg1PwOEfF+3uQngUixHjMzKyLNZxb3BN7Km64DDivsJOki4DKgM3B8sQVJGgWMAthzzz1LXqiZWZa1+cniiJgUEZ8FrgKubaTP5Iioioiq8vLy1i3QzKyDSzMIlgK98qYrkrbGTAG+kmI9ZmZWRJpBUAP0lVQpqTMwDKjO7yCpb97kl4E/p1iPmZkVkdo5gohYK2k0MBMoA+6OiHmSxgO1EVENjJZ0AvAx8C5wdlr1mJlZcWmeLCYiZgAzCtrG5b3+TprrNzOzzWvzk8VmZta2HARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMSzUIJJ0kaaGkRZLGFpl/maT5kl6V9Iyk3mnWY2ZmDaUWBJLKgEnAYKAfMFxSv4JurwBVEfF54GHg5rTqMTOz4tLcIxgILIqIxRGxhtzD6U/N7xARsyLio2TyRXIPuDczs1aUZhD0BN7Km65L2hpzLvBksRmSRkmqlVRbX19fwhLNzGybOFksaQRQBUwsNj8iJkdEVURUlZeXt25xZmYdXJoPr18K9MqbrkjaNiHpBOAa4JiIWJ1iPWZmVkSaewQ1QF9JlZI6A8OA6vwOkvoDdwBDImJ5irWYmVkjUguCiFgLjAZmAguAaRExT9J4SUOSbhOBHYGHJM2RVN3I4szMLCVpHhoiImYAMwraxuW9PiHN9ZuZ2eZtEyeLzcys7TgIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLuFSDQNJJkhZKWiRpbJH5R0v6vaS1ks5IsxYzMysutSCQVAZMAgYD/YDhkvoVdHsTGAk8kFYdZmbWtDQfVTkQWBQRiwEkTQFOBeZv6BARS5J561Osw8zMmpDmoaGewFt503VJW7NJGiWpVlJtfX19SYozM7OcdnGyOCImR0RVRFSVl5e3dTlmZh1KmkGwFOiVN12RtJmZ2TYkzSCoAfpKqpTUGRgGVKe4PjMz2wqpBUFErAVGAzOBBcC0iJgnabykIQCSBkiqA84E7pA0L616zMysuDSvGiIiZgAzCtrG5b2uIXfIyMzM2ki7OFlsZmbpcRCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxqQaBpJMkLZS0SNLYIvN3kDQ1mf+SpD5p1mNmZg2lFgSSyoBJwGCgHzBcUr+CbucC70bE3sAPgQlp1WNmZsWluUcwEFgUEYsjYg0wBTi1oM+pwL3J64eBQZKUYk1mZlYgzWcW9wTeypuuAw5rrE9ErJX0HtAd+Ft+J0mjgFHJ5IeSFqZScYkIelDwN5Tcf2QnL1tle4K3aal5e5Zey7Zp78ZmpPrw+lKJiMnA5LauY0tJqo2Iqrauo6Pw9iw9b9PSau/bM81DQ0uBXnnTFUlb0T6Stgd2BlakWJOZmRVIMwhqgL6SKiV1BoYB1QV9qoGzk9dnAL+OiEixJjMzK5DaoaHkmP9oYCZQBtwdEfMkjQdqI6Ia+Clwn6RFwN/JhUVH0G4OY7UT3p6l521aWu16e8pfwM3Mss13FpuZZZyDwMws4xwEJSRpiaTXJM2RVNvW9bRHku6WtFzS3Ly2XSU9LenPye9PtWWN7Ukj2/N6SUuTz+kcSSe3ZY3tjaRekmZJmi9pnqTvJO3t9nPqICi94yLi4PZ8TXEbuwc4qaBtLPBMRPQFnkmmbcvcQ8PtCfDD5HN6cETMaOWa2ru1wOUR0Q/4AnBRMnxOu/2cOghsmxIR/03uCrJ8+UOR3At8pTVras8a2Z7WAhHxdkT8Pnn9AbCA3CgJ7fZz6iAorQCekvRyMiyGlcbuEfF28vodYPe2LKaDGC3p1eTQUbs5hLGtSUZM7g+8RDv+nDoISuuoiDiE3IirF0k6uq0L6miSGw59zXPL3A58FjgYeBv4QZtW005J2hH4BTAmIt7Pn9fePqcOghKKiKXJ7+XAdHIjsFrLLZO0B0Dye3kb19OuRcSyiFgXEeuBO/HntNkkdSIXAj+PiEeS5nb7OXUQlIikT0rqtuE18EVgbtPvsi2UPxTJ2cBjbVhLu7fhn1Xiq/hz2izJUPk/BRZExC15s9rt59R3FpeIpL3I7QVAbuiOByLixjYsqV2S9CBwLLlhfZcB/w48CkwD9gTeAM6KCJ8A3QKNbM9jyR0WCmAJcH7esW3bDElHAc8BrwHrk+aryZ0naJefUweBmVnG+dCQmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPA2gVJIekHedNXSLq+RMu+R9IZpVjWZtZzpqQFkmYVtPeR9LUWLvv5llVnWeYgsPZiNXCapB5tXUg+Sc153Ou5wLci4riC9j5Ai4IgIo5oyfst2xwE1l6sJfdc2EsLZxR+o5f0YfL7WEnPSnpM0mJJN0n6uqTfJc+N+GzeYk6QVCvpT5JOSd5fJmmipJpkgLbz85b7nKRqYH6ReoYny58raULSNg44CvippIkFb7kJ+Jfk2QCXSuoi6WfJMl6RdFyyjJHJ3zI7GfP+3wv/5uT1Vcl7/yDppqTtkmT8/FclTWnOhreOL7WH15ulYBLwqqSbm/Geg4D9yA3FvBi4KyIGJg8TuRgYk/TrQ27Mnc8CsyTtDXwDeC8iBkjaAfitpKeS/ocAB0TE6/krk/QZYAJwKPAuudFovxIR4yUdD1wREYUPLRqbtG8IoMvJjVt2oKR9k2Xsk/QdCBwAfATUSHoif3mSBpMbDvmwiPhI0q5566iMiNWSdmnG9rMM8B6BtRvJCI//CVzSjLfVJOPHrwb+Amz4R/4auX/+G0yLiPUR8WdygbEvufGiviFpDrnhA7oDfZP+vysMgcQAYHZE1EfEWuDnQHNHoT0KuB8gIv5IbriCDUHwdESsiIiVwCNJ33wnAD+LiI+S928Y4uBV4OeSRpDbuzLbyEFg7c2t5I61fzKvbS3JZ1nSdkDnvHmr816vz5tez6Z7xIVjrQQg4OK8J3lVRsSGIPlnS/6IFihW55b4Mrk9qkPI7Un4aIBt5CCwdiX5hjuNXBhssITcoRiAIUCnrVj0mZK2S84b7AUsBGYCFyZDDiNpn2Rk2ab8DjhGUg9JZcBw4NnNvOcDoFve9HPA1zesk9wgZguTeScmz8btSu4JWL8tWNbTwDclfSJ5/65JOPaKiFnAVcDOwI6bqckyxN8KrD36ATA6b/pO4DFJfwB+ydZ9W3+T3D/xnYALImKVpLvIHT76fTL0cD2befxgRLwtaSwwi9wexRMRsbnhiF8F1iX13wP8GLhd0mvk9nZGJsf2SWr8BVAB3F94viEifinpYKBW0hpgBrkRR++XtHNS048i4h+b3SKWGR591KydkDQSqIqI0Zvra9YcPjRkZpZx3iMwM8s47xGYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnG/Q9hk10ylJ8HOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classic_keys = list(results['tus']['classic corpus'].keys())\n",
    "extended_keys = list(results['tus']['extended corpus'].keys())\n",
    "\n",
    "classic_values = list(results['tus']['classic corpus'].values())\n",
    "extended_values = list(results['tus']['extended corpus'].values())\n",
    "\n",
    "x_values = range(len(classic_keys))\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "model_string = \"LDA\" if use_lda else \"NMF\"\n",
    "\n",
    "# plot the bars for the classic dictionary values\n",
    "plt.bar(x_values, classic_values, align='edge', width=-bar_width, alpha=1, label=f'Classic {model_string}')\n",
    "\n",
    "# plot the bars for the new dictionary values\n",
    "plt.bar(x_values, extended_values, align='edge', width=bar_width, alpha=1, label=f'NER + {model_string}')\n",
    "\n",
    "# set the x-axis ticks and labels\n",
    "plt.xticks(x_values, classic_keys)\n",
    "\n",
    "# add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "Y_str = \"TUS\"\n",
    "\n",
    "# set the y-axis label\n",
    "plt.ylabel(Y_str)\n",
    "\n",
    "# set the x-axis label\n",
    "plt.xlabel('Number of topics')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f0d7ebe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classic_keys = list(results['js']['classic corpus'].keys())\n",
    "extended_keys = list(results['js']['extended corpus'].keys())\n",
    "\n",
    "classic_values = list(results['js']['classic corpus'].values())\n",
    "extended_values = list(results['js']['extended corpus'].values())\n",
    "\n",
    "x_values = range(len(classic_keys))\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "model_string = \"LDA\" if use_lda else \"NMF\"\n",
    "\n",
    "# plot the bars for the classic dictionary values\n",
    "plt.bar(x_values, classic_values, align='edge', width=-bar_width, alpha=1, label=f'Classic {model_string}')\n",
    "\n",
    "# plot the bars for the new dictionary values\n",
    "plt.bar(x_values, extended_values, align='edge', width=bar_width, alpha=1, label=f'NER + {model_string}')\n",
    "\n",
    "# set the x-axis ticks and labels\n",
    "plt.xticks(x_values, classic_keys)\n",
    "\n",
    "# add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "Y_str = \"Jensen-Shannon Divergence\" \n",
    "\n",
    "# set the y-axis label\n",
    "plt.ylabel(Y_str)\n",
    "\n",
    "# set the x-axis label\n",
    "plt.xlabel('Number of topics')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c852a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
